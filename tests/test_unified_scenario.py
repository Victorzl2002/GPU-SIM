"""
ç»Ÿä¸€æµ‹è¯•åœºæ™¯ï¼šå¼‚æ„GPUæ± åŒ–ç³»ç»Ÿ

æµ‹è¯•åœºæ™¯ï¼š
- 2ä¸ªèŠ‚ç‚¹ï¼šNVIDIAèŠ‚ç‚¹ã€åä¸ºèŠ‚ç‚¹
- æ¯ä¸ªèŠ‚ç‚¹5å¼ GPUå¡
- é¢„å®šä¹‰çš„ä»»åŠ¡é›†åˆ
- ç»Ÿä¸€çš„æµ‹è¯•æµç¨‹
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.vgpu_model.resource_model.vgpu_resource import VGPUResource, ResourceType
from core.vgpu_model.resource_model.resource_mapper import ResourceMapper
from core.vgpu_model.resource_model.resource_allocator import ResourceAllocator
from core.vgpu_model.normalization.normalization_coefficients import (
    NormalizationCoefficients, CoefficientManager
)
from core.vgpu_model.normalization.cross_vendor_scorer import CrossVendorScorer
from core.vgpu_model.normalization.platform_benchmark import PlatformBenchmark


class UnifiedTestScenario:
    """ç»Ÿä¸€æµ‹è¯•åœºæ™¯ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•åœºæ™¯"""
        self.nodes = {}
        self.tasks = []
        self.coeff_manager = CoefficientManager()
        self.scorer = CrossVendorScorer()
        self.mapper = ResourceMapper()
        self.allocator = ResourceAllocator()
        
        # åˆå§‹åŒ–æ•°æ®
        self._init_nodes()
        self._init_tasks()
        self._init_coefficients()
        self._init_allocator()
    
    def _init_nodes(self):
        """åˆå§‹åŒ–èŠ‚ç‚¹å’ŒGPUå¡"""
        print("åˆå§‹åŒ–èŠ‚ç‚¹å’ŒGPUå¡...")
        
        # èŠ‚ç‚¹1ï¼šNVIDIAèŠ‚ç‚¹
        nvidia_node = {
            'node_id': 'nvidia_node_001',
            'vendor': 'nvidia',
            'location': 'datacenter_a',
            'gpus': []
        }
        
        # NVIDIAèŠ‚ç‚¹5å¼ A100å¡
        for i in range(5):
            gpu = VGPUResource(
                compute=312.0,    # TFLOPS
                memory=80.0,      # GB
                bandwidth=2039.0, # GB/s
                resource_id=f"nvidia_a100_{i+1:02d}",
                vendor="nvidia",
                model="A100"
            )
            nvidia_node['gpus'].append(gpu)
        
        # èŠ‚ç‚¹2ï¼šåä¸ºèŠ‚ç‚¹
        huawei_node = {
            'node_id': 'huawei_node_001', 
            'vendor': 'huawei',
            'location': 'datacenter_b',
            'gpus': []
        }
        
        # åä¸ºèŠ‚ç‚¹5å¼ Ascend 910Bå¡
        for i in range(5):
            gpu = VGPUResource(
                compute=280.0,    # TFLOPS
                memory=64.0,      # GB
                bandwidth=1600.0, # GB/s
                resource_id=f"huawei_ascend_{i+1:02d}",
                vendor="huawei",
                model="Ascend910B"
            )
            huawei_node['gpus'].append(gpu)
        
        self.nodes = {
            'nvidia_node_001': nvidia_node,
            'huawei_node_001': huawei_node
        }
        
        print(f"âœ… åˆå§‹åŒ–å®Œæˆï¼š{len(self.nodes)}ä¸ªèŠ‚ç‚¹ï¼Œ{sum(len(node['gpus']) for node in self.nodes.values())}å¼ GPUå¡")
    
    def _init_tasks(self):
        """åˆå§‹åŒ–é¢„å®šä¹‰ä»»åŠ¡"""
        print("åˆå§‹åŒ–é¢„å®šä¹‰ä»»åŠ¡...")
        
        # ä»»åŠ¡1ï¼šæ·±åº¦å­¦ä¹ è®­ç»ƒä»»åŠ¡
        task1 = {
            'task_id': 'dl_training_001',
            'task_type': 'deep_learning',
            'priority': 'high',
            'description': 'ResNet-50å›¾åƒåˆ†ç±»è®­ç»ƒ',
            'demand': VGPUResource(
                compute=200.0,    # éœ€è¦200 TFLOPS
                memory=50.0,      # éœ€è¦50GBæ˜¾å­˜
                bandwidth=800.0,  # éœ€è¦800 GB/så¸¦å®½
                resource_id='dl_training_001_demand'
            )
        }
        
        # ä»»åŠ¡2ï¼šæ¨¡å‹æ¨ç†ä»»åŠ¡
        task2 = {
            'task_id': 'inference_001',
            'task_type': 'inference',
            'priority': 'medium',
            'description': 'BERTæ–‡æœ¬åˆ†ç±»æ¨ç†',
            'demand': VGPUResource(
                compute=120.0,
                memory=30.0,
                bandwidth=600.0,
                resource_id='inference_001_demand'
            )
        }
        
        # ä»»åŠ¡3ï¼šå¤§æ¨¡å‹è®­ç»ƒä»»åŠ¡
        task3 = {
            'task_id': 'llm_training_001',
            'task_type': 'training',
            'priority': 'high',
            'description': 'GPT-3è¯­è¨€æ¨¡å‹è®­ç»ƒ',
            'demand': VGPUResource(
                compute=250.0,
                memory=60.0,
                bandwidth=1000.0,
                resource_id='llm_training_001_demand'
            )
        }
        
        # ä»»åŠ¡4ï¼šç§‘å­¦è®¡ç®—ä»»åŠ¡
        task4 = {
            'task_id': 'scientific_001',
            'task_type': 'deep_learning',
            'priority': 'low',
            'description': 'åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿ',
            'demand': VGPUResource(
                compute=180.0,
                memory=40.0,
                bandwidth=700.0,
                resource_id='scientific_001_demand'
            )
        }
        
        # ä»»åŠ¡5ï¼šæ‰¹å¤„ç†ä»»åŠ¡
        task5 = {
            'task_id': 'batch_001',
            'task_type': 'inference',
            'priority': 'low',
            'description': 'å›¾åƒæ‰¹å¤„ç†æ¨ç†',
            'demand': VGPUResource(
                compute=100.0,
                memory=25.0,
                bandwidth=500.0,
                resource_id='batch_001_demand'
            )
        }
        
        self.tasks = [task1, task2, task3, task4, task5]
        print(f"âœ… åˆå§‹åŒ–å®Œæˆï¼š{len(self.tasks)}ä¸ªé¢„å®šä¹‰ä»»åŠ¡")
    
    def _init_coefficients(self):
        """åˆå§‹åŒ–æŠ˜ç®—ç³»æ•°"""
        print("åˆå§‹åŒ–æŠ˜ç®—ç³»æ•°...")
        
        # NVIDIA A100 æŠ˜ç®—ç³»æ•° (ä»¥A100ä¸ºåŸºå‡†)
        nvidia_coeff = NormalizationCoefficients(
            alpha=1.0,      # ç®—åŠ›æŠ˜ç®—ç³»æ•°
            beta=1.0,       # æ˜¾å­˜æŠ˜ç®—ç³»æ•°  
            gamma=1.0,      # å¸¦å®½æŠ˜ç®—ç³»æ•°
            vendor="nvidia",
            model="A100",
            baseline="nvidia_a100"
        )
        
        # åä¸º Ascend 910B æŠ˜ç®—ç³»æ•°
        huawei_coeff = NormalizationCoefficients(
            alpha=0.9,      # ç®—åŠ›ç›¸å¯¹A100çš„æŠ˜ç®—ç³»æ•°
            beta=0.8,       # æ˜¾å­˜ç›¸å¯¹A100çš„æŠ˜ç®—ç³»æ•°
            gamma=0.78,     # å¸¦å®½ç›¸å¯¹A100çš„æŠ˜ç®—ç³»æ•°
            vendor="huawei",
            model="Ascend910B",
            baseline="nvidia_a100"
        )
        
        # æ·»åŠ æŠ˜ç®—ç³»æ•°
        self.coeff_manager.add_coefficients(nvidia_coeff)
        self.coeff_manager.add_coefficients(huawei_coeff)
        
        print(f"âœ… æŠ˜ç®—ç³»æ•°åˆå§‹åŒ–å®Œæˆ")
    
    def _init_allocator(self):
        """åˆå§‹åŒ–èµ„æºåˆ†é…å™¨"""
        print("åˆå§‹åŒ–èµ„æºåˆ†é…å™¨...")
        
        # å°†æ‰€æœ‰GPUæ·»åŠ åˆ°åˆ†é…å™¨
        for node_id, node in self.nodes.items():
            for gpu in node['gpus']:
                self.allocator.add_available_resource(gpu)
        
        print(f"âœ… èµ„æºåˆ†é…å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def display_scenario(self):
        """æ˜¾ç¤ºæµ‹è¯•åœºæ™¯"""
        print("\n" + "=" * 80)
        print("ç»Ÿä¸€æµ‹è¯•åœºæ™¯æ¦‚è§ˆ")
        print("=" * 80)
        
        # æ˜¾ç¤ºèŠ‚ç‚¹ä¿¡æ¯
        for node_id, node in self.nodes.items():
            print(f"\nèŠ‚ç‚¹: {node_id}")
            print(f"  å‚å•†: {node['vendor']}")
            print(f"  ä½ç½®: {node['location']}")
            print(f"  GPUæ•°é‡: {len(node['gpus'])}")
            
            for i, gpu in enumerate(node['gpus'], 1):
                print(f"    GPU{i}: {gpu.resource_id} - {gpu}")
        
        # æ˜¾ç¤ºä»»åŠ¡ä¿¡æ¯
        print(f"\né¢„å®šä¹‰ä»»åŠ¡ ({len(self.tasks)}ä¸ª):")
        for task in self.tasks:
            print(f"  {task['task_id']}: {task['description']}")
            print(f"    ç±»å‹: {task['task_type']}, ä¼˜å…ˆçº§: {task['priority']}")
            print(f"    éœ€æ±‚: {task['demand']}")
    
    def test_cross_vendor_scoring(self):
        """æµ‹è¯•è·¨å‚å•†å¾—åˆ†è®¡ç®—"""
        print("\n" + "=" * 80)
        print("è·¨å‚å•†å¾—åˆ†è®¡ç®—æµ‹è¯•")
        print("=" * 80)
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªä»»åŠ¡è¿›è¡Œæµ‹è¯•
        test_task = self.tasks[0]
        print(f"æµ‹è¯•ä»»åŠ¡: {test_task['task_id']} - {test_task['description']}")
        print(f"ä»»åŠ¡éœ€æ±‚: {test_task['demand']}")
        
        # è®¡ç®—ä»»åŠ¡åœ¨æ‰€æœ‰GPUä¸Šçš„å¾—åˆ†
        all_gpus = []
        for node in self.nodes.values():
            all_gpus.extend(node['gpus'])
        
        print(f"\nè®¡ç®—ä»»åŠ¡åœ¨{len(all_gpus)}å¼ GPUä¸Šçš„å¾—åˆ†:")
        
        gpu_scores = []
        for gpu in all_gpus:
            try:
                score = self.scorer.calculate_cross_vendor_score(test_task['demand'], gpu)
                gpu_scores.append((gpu, score))
                print(f"  {gpu.resource_id}: {score:.6f}")
            except Exception as e:
                print(f"  {gpu.resource_id}: è®¡ç®—å¤±è´¥ - {e}")
        
        # æ’åºå¹¶æ˜¾ç¤ºç»“æœ
        gpu_scores.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nGPUå¾—åˆ†æ’å:")
        for i, (gpu, score) in enumerate(gpu_scores, 1):
            print(f"  ç¬¬{i}å: {gpu.resource_id} - å¾—åˆ†: {score:.6f}")
        
        return gpu_scores
    
    def test_task_scheduling(self):
        """æµ‹è¯•ä»»åŠ¡è°ƒåº¦"""
        print("\n" + "=" * 80)
        print("ä»»åŠ¡è°ƒåº¦æµ‹è¯•")
        print("=" * 80)
        
        scheduling_results = []
        
        for task in self.tasks:
            print(f"\nè°ƒåº¦ä»»åŠ¡: {task['task_id']}")
            print(f"  æè¿°: {task['description']}")
            print(f"  éœ€æ±‚: {task['demand']}")
            
            # ä¸ºä»»åŠ¡é€‰æ‹©æœ€ä½³GPU
            best_gpu = None
            best_score = 0
            available_gpus = []
            
            # è·å–æ‰€æœ‰å¯ç”¨GPU
            for node in self.nodes.values():
                for gpu in node['gpus']:
                    if gpu.resource_id in self.allocator.get_available_resources():
                        available_gpus.append(gpu)
            
            # è®¡ç®—å¾—åˆ†å¹¶é€‰æ‹©æœ€ä½³GPU
            for gpu in available_gpus:
                try:
                    score = self.scorer.calculate_cross_vendor_score(task['demand'], gpu)
                    print(f"    {gpu.resource_id}: å¾—åˆ† = {score:.6f}")
                    
                    if score > best_score:
                        best_score = score
                        best_gpu = gpu
                except Exception as e:
                    print(f"    {gpu.resource_id}: è®¡ç®—å¤±è´¥ - {e}")
            
            if best_gpu:
                # å°è¯•åˆ†é…èµ„æº
                allocated = self.allocator.allocate_resource(best_gpu.resource_id, task['demand'])
                if allocated:
                    print(f"  âœ… æˆåŠŸåˆ†é…åˆ°: {best_gpu.resource_id}")
                    print(f"  ğŸ“ˆ åˆ†é…èµ„æº: {allocated}")
                    
                    scheduling_results.append({
                        'task': task,
                        'gpu': best_gpu,
                        'score': best_score,
                        'allocated': allocated,
                        'success': True
                    })
                else:
                    print(f"  âŒ åˆ†é…å¤±è´¥")
                    scheduling_results.append({
                        'task': task,
                        'gpu': best_gpu,
                        'score': best_score,
                        'allocated': None,
                        'success': False
                    })
            else:
                print(f"  âŒ æ— å¯ç”¨GPU")
                scheduling_results.append({
                    'task': task,
                    'gpu': None,
                    'score': 0,
                    'allocated': None,
                    'success': False
                })
        
        return scheduling_results
    
    def test_resource_utilization(self):
        """æµ‹è¯•èµ„æºåˆ©ç”¨ç‡"""
        print("\n" + "=" * 80)
        print("èµ„æºåˆ©ç”¨ç‡æµ‹è¯•")
        print("=" * 80)
        
        # è·å–èµ„æºåˆ©ç”¨ç‡
        utilization = self.allocator.get_resource_utilization()
        
        print("å„GPUèµ„æºåˆ©ç”¨ç‡:")
        for gpu_id, util in utilization.items():
            print(f"\n{gpu_id}:")
            print(f"  ç®—åŠ›åˆ©ç”¨ç‡: {util['compute_utilization']*100:.1f}%")
            print(f"  æ˜¾å­˜åˆ©ç”¨ç‡: {util['memory_utilization']*100:.1f}%")
            print(f"  å¸¦å®½åˆ©ç”¨ç‡: {util['bandwidth_utilization']*100:.1f}%")
        
        # è®¡ç®—æ€»ä½“åˆ©ç”¨ç‡
        total_util = {}
        for util in utilization.values():
            for key, value in util.items():
                if key not in total_util:
                    total_util[key] = []
                total_util[key].append(value)
        
        print(f"\næ€»ä½“èµ„æºåˆ©ç”¨ç‡:")
        for key, values in total_util.items():
            avg_util = sum(values) / len(values)
            print(f"  å¹³å‡{key}: {avg_util*100:.1f}%")
    
    def test_node_performance(self):
        """æµ‹è¯•èŠ‚ç‚¹æ€§èƒ½å¯¹æ¯”"""
        print("\n" + "=" * 80)
        print("èŠ‚ç‚¹æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
        print("=" * 80)
        
        # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„æ€»èµ„æº
        for node_id, node in self.nodes.items():
            print(f"\nèŠ‚ç‚¹: {node_id}")
            
            # è®¡ç®—èŠ‚ç‚¹æ€»èµ„æº
            total_compute = sum(gpu.compute for gpu in node['gpus'])
            total_memory = sum(gpu.memory for gpu in node['gpus'])
            total_bandwidth = sum(gpu.bandwidth for gpu in node['gpus'])
            
            print(f"  æ€»ç®—åŠ›: {total_compute} TFLOPS")
            print(f"  æ€»æ˜¾å­˜: {total_memory} GB")
            print(f"  æ€»å¸¦å®½: {total_bandwidth} GB/s")
            
            # è®¡ç®—èŠ‚ç‚¹å¾—åˆ†ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªä»»åŠ¡ä½œä¸ºåŸºå‡†ï¼‰
            test_task = self.tasks[0]['demand']
            node_scores = []
            
            for gpu in node['gpus']:
                try:
                    score = self.scorer.calculate_cross_vendor_score(test_task, gpu)
                    node_scores.append(score)
                except:
                    node_scores.append(0)
            
            avg_score = sum(node_scores) / len(node_scores)
            print(f"  å¹³å‡å¾—åˆ†: {avg_score:.6f}")
            print(f"  æœ€é«˜å¾—åˆ†: {max(node_scores):.6f}")
            print(f"  æœ€ä½å¾—åˆ†: {min(node_scores):.6f}")
    
    def run_complete_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ç»Ÿä¸€æµ‹è¯•åœºæ™¯")
        
        # 1. æ˜¾ç¤ºåœºæ™¯æ¦‚è§ˆ
        self.display_scenario()
        
        # 2. æµ‹è¯•è·¨å‚å•†å¾—åˆ†è®¡ç®—
        gpu_scores = self.test_cross_vendor_scoring()
        
        # 3. æµ‹è¯•ä»»åŠ¡è°ƒåº¦
        scheduling_results = self.test_task_scheduling()
        
        # 4. æµ‹è¯•èµ„æºåˆ©ç”¨ç‡
        self.test_resource_utilization()
        
        # 5. æµ‹è¯•èŠ‚ç‚¹æ€§èƒ½å¯¹æ¯”
        self.test_node_performance()
        
        # 6. æµ‹è¯•ç»“æœæ€»ç»“
        print("\n" + "=" * 80)
        print("æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 80)
        
        successful_tasks = sum(1 for result in scheduling_results if result['success'])
        total_tasks = len(scheduling_results)
        
        print(f"ä»»åŠ¡è°ƒåº¦æˆåŠŸç‡: {successful_tasks}/{total_tasks} ({successful_tasks/total_tasks*100:.1f}%)")
        
        # æŒ‰èŠ‚ç‚¹ç»Ÿè®¡
        node_stats = {}
        for result in scheduling_results:
            if result['success'] and result['gpu']:
                node_id = result['gpu'].resource_id.split('_')[0] + '_' + result['gpu'].resource_id.split('_')[1]
                if node_id not in node_stats:
                    node_stats[node_id] = 0
                node_stats[node_id] += 1
        
        print(f"\nå„èŠ‚ç‚¹ä»»åŠ¡åˆ†é…ç»Ÿè®¡:")
        for node_id, count in node_stats.items():
            print(f"  {node_id}: {count}ä¸ªä»»åŠ¡")
        
        print(f"\nâœ… ç»Ÿä¸€æµ‹è¯•åœºæ™¯å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºç»Ÿä¸€æµ‹è¯•åœºæ™¯
        scenario = UnifiedTestScenario()
        
        # è¿è¡Œå®Œæ•´æµ‹è¯•
        scenario.run_complete_test()
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

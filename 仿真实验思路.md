<!--
 * @Author: Victorzl
 * @Date: 2025-11-10 15:10:31
 * @LastEditors: Victorzl
 * @LastEditTime: 2025-11-11 13:52:34
 * @Description: 请填写简介
-->

## **步骤 0：总体思路锁定（你到底在模拟什么）**

你要模拟的是：

1. 多厂商异构 GPU 组成的统一 vGPU 池；

2. GLB 两级调度（选厂商 + LRP+BRA 节点打分）给出**静态配额**；

3. API 沙盒三门（显存配额门 / 带宽令牌桶 / 计算节流门）在 tick 级别做**动态限流**；

4. 多种策略（A1/A2/A2P/A3/A4/A5）在同一工作负载下的表现差异：

   - GPU 利用率
   - SLO 满足率
   - 干扰率 / 尾部稳定性
   - 三门协同对抖动的改善程度

整个实验是**离散时间仿真**：不真实跑模型，用公式推进任务进度 + 资源占用。

---

## **步骤 1：搭建仿真基础框架**

1. 语言环境：Python 3.x（你现在已经有）。

2. 时间推进：

   - 定义仿真时间步长 Δt（如 10 ms）。
   - 定义总时长 $T_end$（如 600 s / 3600 s），仿真 tick 数 $N_tick = T_end / Δt$。

3. 核心对象：

   - GPU：记录等效容量、已用资源；
   - Node：多个 GPU 聚合、链路带宽；
   - Task：需求向量、SLO、进度、状态；
   - Scheduler(GLB)：做节点过滤 + 打分；
   - Sandbox：三门限流逻辑；
   - Metrics：收集日志并计算指标。

> 仿真是“事件驱动+时间片”：每个 tick 做“任务到达 → 调度 → 沙盒限流 → 推进进度 → 记录指标”。

---

## **步骤 2：定义异构 GPU 与 vGPU 模型**

### **2.1 定义物理 GPU 参数**

对每种 GPU（A100, 910B, 其他）给出真实参数：

- $C_v$：TFLOPS（单精度 or 混合精度，选论文里的一致口径）
- $M_v$：显存容量（GB）
- $B_v$：有效带宽（GB/s，含 NVLink/HCCS/PCIe）

### **2.2 容量归一化**

选基准 GPU（如 A100@CUDA）：

- 归一化：$\hat C_v = C_v / C_{\text{ref}}$ 等价地对 M, B 归一化。
- 得到归一化向量 $D_v = (\hat C_v, \hat M_v, \hat B_v)$。

### **2.3 软件折算系数 (α, β, γ)**

为每个**平台 v** 配置：

- $\alpha_v, \beta_v, \gamma_v$：来自公开规格 +文献+你前面标定方案；
- 等效容量：$\tilde D_v = (\alpha_v \hat C_v, \beta_v \hat M_v, \gamma_v \hat B_v)$。

仿真里直接把这组数**写死成配置**，说明“来源于离线基准测试 / 文档标定”。

### **2.4 集群构建**

- 若干节点，每个节点挂若干张 GPU，单节点同厂商更清晰。
- 节点总容量 = 所有 GPU 等效容量向量求和。

---

## **步骤 3：构造任务工作负载**

### **3.1 任务属性**

为每个任务 $T_i$ 设置：

- 资源需求基向量 $d_i = (c_i, m_i, b_i)$：单位为“相对比例”（0~1）或绝对需求（TFLOPS, GB, GB/s）。
- 兼容性：
  - type = cuda-only / cann-only / both（用 $x_{i,v}$ 描述是否可在平台 v 运行）。
- 并行度参数：
  - $k_min, k_max$（本论文里通常约束为“同节点多卡，不跨节点”）。
- SLO：
  - $L_i$：延迟/完成时限或 p95 阈值；
- 计算量：
  - $W_i$：总“工作量单位”，仿真中每 tick 按分配算力推进。
- 到达过程：
  - $arrival_time$：可用泊松、批量到达、突发场景等。

### **3.2 任务到达生成**

- 在主循环开始前生成一串任务列表（含到达时间）。
- 每个 tick：将 $arrival_time == t$ 的任务加入待调度队列。

---

## **步骤 4：实现 GLB 两级调度**

> 这一部分是把你图片里 4.2–4.3 的内容程序化；注意：**选厂商 + 节点打分**。

### **4.1 预处理：任务最适配 GPU 类型**

离线或仿真初始化时，对每个任务类型 i：

- 根据 “perf[i,v]”（来自压测/文档比值）计算性价比分：

  $score\_{type}(i,v) = \frac{\text{吞吐或速率}(i,v)}{\text{单位等效容量消耗}(i,v)}$

- 取 $argmax_v$ 作为任务 i 的“最适配 GPU 类型” v\*。

- 仿真中：任务只匹配节点上该类型（或兼容集合）GPU。

### **4.2 节点过滤 (filter_nodes)**

对待调度任务 t：

1. 采样部分节点（sampling_ratio, min_candidates）。
2. 过滤条件：
   - 节点剩余等效资源 ≥ 任务需求；
   - 节点含有匹配的 GPU 类型；
3. 若无可用节点：
   - 将任务放回队尾（模拟排队 / 等待下个 tick）。

### **4.3 LRP 得分（资源剩余越多得分越大）**

对每个候选节点 n：

- 计算节点的“使用比例”：

  $u_{n,r} = \frac{\text{used}{n,r}}{\text{cap}{n,r}}, \quad r \in \{C,M,B\}$

  表示节点在计算、显存、带宽三个维度上的使用率。

- LRP 得分表示“资源越空闲得分越高”，定义为：

  $score^{LRP}{t,n} = \frac{10}{3} \sum{r\in\{C,M,B\}} \left(\frac{a_{n,r} - q_{t,r}}{c_{n,r}}\right)$

  其中：

  - $a_{n,r}$：节点 n 在维度 r 上的可用资源；
  - $q_{t,r}$：任务 t 在维度 r 上的资源需求；
  - $c_{n,r}$：节点 n 的总容量；
  - 结果映射到区间 [0,10]，值越大表示节点越空闲。

---

### **4.4 BRA 得分（资源使用越平衡得分越高）**

取节点 n 当前三维使用比例：

$(u_C, u_M, u_B) = \left( \frac{\text{used}{n,C}}{\text{cap}{n,C}}, \frac{\text{used}{n,M}}{\text{cap}{n,M}}, \frac{\text{used}{n,B}}{\text{cap}{n,B}} \right)$

计算其方差：

$Var_n = variance(u_C, u_M, u_B)$

将其映射成 0–10 分：

$score^{BRA}_{t,n} = 10 \cdot (1 - Var_n)$

差异越小，说明资源越均衡，得分越高。

---

### **4.5 综合得分与贪心分配（GLB）**

综合 LRP 与 BRA 得分：

$score_{t,n} = \lambda \cdot score^{LRP}{t,n} + (1 - \lambda) \cdot score^{BRA}{t,n}$

其中 $\lambda \in [0,1]$ 为平衡权重，一般可取 0.5。

---

**贪心分配过程**：

对于每个待调度任务 t，选得分最高的节点：

$n^* = \arg\max_{n \in N_{v^*}} score_{t,n}$

并分配其对应的三维配额上限：

$Q_t = (Q^C_t, Q^M_t, Q^B_t)$

作为后续沙盒执行层的静态预算。

---

## **步骤 5：实现 API 沙盒三门（离散时间）**

在仿真环境中给每个**已调度任务**配一份 state：

- 当前显存占用 $M_i(t)$
- 当前带宽发送速率 $B_i(t)$
- 当前算力推进速率 $E_i(t)$
- 对应的配额上限 $Q_i = (Q^C_i, Q^M_i, Q^B_i)$ 来自 GLB

### **5.1 显存配额门**

每个 tick：

1. 生成该任务“本 tick 期望新增显存请求” $R_i(t)$
   - 可简单设为：与任务阶段或 batch 大小相关的常量/分布。
2. 判断：
   - 若 $M_i(t) + R_i(t) \le Q^M_i$：允许，$M_i += R_i$；
   - 否则：拒绝或推迟（排队），记为被限流。
3. 统计滑动窗口内 $M_i(t)$ 的均值与方差，得到 $σ_i^M$，供稳定性指标使用。

### **5.2 带宽令牌桶**

每个任务维护：

- 令牌数 $τ_i(t)$、补充速率 $r_i$、突发上限 $τ_max$。

每 tick：

1. 令牌更新：$τ_i = min(τ_max, τ_i + r_i·Δt - 已用带宽)$；
2. 若任务希望发送 $X_i(t)$：
   - $实际放行 = min(X_i(t), τ_i)$，否则剩余排队；
3. 更新 $B_i(t)$，记录波动度 $σ_i^B$ 和利用率。

### **5.3 计算节流门**

每 tick：

1. 理论可用算力：不超过 $Q^C_i$，也不超过节点剩余；
2. 若任务“想用”的算力 $E_raw(t) > Q^C_i$：
   - 实际推进速率 $E_i(t) = 按节流公式收敛到 Q^C_i 附近$；
3. 按 $E_i(t)$ 推进任务进度：$progress += E_i(t) * Δt / W_i$；
4. 完成条件：progress ≥ 1 → 记录完成时间，任务结束。
5. 统计 $σ_i^C$。

---

## **步骤 6：主循环（离散时间仿真）**

对每个 $tick t=0..N_tick$：

1. **任务到达：** 将到达的任务放入队列。

2. **调度阶段（GLB）：**

   - 对尚未绑定节点的任务，调用 GLB：
     - 过滤可行节点（采样+资源检查）；
     - 按 LRP+BRA 打分，贪心选择 $best_node$；
     - 分配三维配额 $Q_i$，更新节点剩余。

3. **沙盒执行阶段：**

   - 对所有运行中的任务：
     - 显存配额门：更新 $M_i$；
     - 带宽令牌桶：更新 $B_i$；
     - 计算节流门：算力推进，更新 progress 与状态。

4. **任务完成/超时检查：**

   - 记录完成时间、是否满足 SLO；

5. **监测与统计：**

   - 记录每 tick：
     - 每节点 C/M/B 利用率；
     - 每任务延迟样本；
     - 是否被限流（显存/带宽/算力）；
   - 用于之后计算 SLO rate、IR、稳定性指标。

6. **（闭环变体时）参数调整：**

   - 若采用 A3 闭环：每隔若干 tick 根据全局 S 稳定性指标微调配额/令牌参数或 GLB 权重。

---

## **步骤 7：实验场景配置**

你论文里的几组对照要都在这个框架里实现：

1. **A1 无隔离基线**

   - 有 GLB 调度（或简单调度），**无三门限流**；
   - 只要节点容量够就放行，观察干扰与 SLO 崩掉程度。

2. **A2 硬切分（MIG 近似）**

   - 将 GPU 容量静态切成固定分片；
   - 每任务独占分片，不共用；
   - 无沙盒，利用率会比较低。

3. **A2P ParvaGPU 近似**

   - 模拟论文里的固定切片 + 部分共享策略；
   - 仍然没有 API 三门，但比 A2 灵活。

4. **A3 API 沙盒 + GLB**

   - 使用 GLB 调度 + 显存门 + 带宽桶 + 计算节流；

   - 分开做：

     - 开环：不根据 SLO 调回；
     - 闭环：根据稳定性指标 S 做小幅调参。

5. **A4 去链路门消融**

   - 在 A3 基础上去掉令牌桶，只靠显存门+算力门；
   - 看链路拥塞和尾延迟恶化。

6. **A5 去 SLO 守护消融**

   - A3 结构但不做闭环调参；
   - 看无反馈时的稳定性下降。

---

## **步骤 8：指标计算（实验结束时统一算）**

1. **SLO 满足率**

   - 目标型：$\text{SLO\_rate} = \frac{1}{N}\sum 1[T_i \text{ 完成延迟} \le L_i]$

2. **干扰率 IR**

   - 对每任务：实际完成时间 / 理想（独占）完成时间；
   - I$R_i > 1$ 即受到干扰；
   - 统计均值 $\overline{IR} 和 p95（或 p05 of IR^{-1}）$等。

3. **GPU 利用率**

   - 对每节点、每种资源 r：

     - $\text{Util}_r = \frac{\sum_t \text{used}_r(t)}{\sum_t \text{cap}_r}$

4. **稳定性指标（波动度）**

   - 显存：$σ_i^M$；带宽：$σ_i^B；$算力：$σ_i^C$；
   - 综合：$\sigma_i^{all} = w_M σ_i^M + w_B σ_i^B + w_C σ_i^C$
   - 全局：S = Var(p95) + λ·平均干扰率。

5. **对比展示**

   - 各策略的：$SLO_rate, Util, IR, S$；
   - 曲线：负载从 0.3→0.9 的扫描、突发场景。

---
